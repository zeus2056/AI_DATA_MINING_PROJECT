{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "OUL6VoPVS194",
        "outputId": "aeb7be66-d42f-4cf8-e8e1-8af9c9553f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/175.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m174.1/175.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://403b5b535993d04b3d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://403b5b535993d04b3d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install gradio transformers scikit-learn emoji \"clean-text[gpl]\" --quiet\n",
        "import os\n",
        "import re\n",
        "import gradio as gr\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from emoji import demojize\n",
        "from cleantext import clean\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/SENTIEMENT_MODEL/bert_turk_sentiment_model\"\n",
        "\n",
        "files = os.listdir(MODEL_PATH)\n",
        "\n",
        "if not any(x in files for x in [\"vocab.json\", \"sentencepiece.bpe.model\", \"tokenizer.json\"]):\n",
        "    print(\"Tokenizer klasörde bulunamadı → indiriliyor...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert_turk_sentiment_model\")\n",
        "    tokenizer.save_pretrained(MODEL_PATH)\n",
        "else:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=False)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device).eval()\n",
        "\n",
        "id2label = {0: \"Negative\", 1: \"Notr\", 2: \"Positive\"}\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "\n",
        "    text = demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = text.replace(\"_\", \" \")\n",
        "\n",
        "    text = clean(\n",
        "        text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        no_emoji=True,\n",
        "        no_line_breaks=True,\n",
        "        replace_with_url=\" \",\n",
        "        replace_with_email=\" \",\n",
        "        replace_with_phone_number=\" \",\n",
        "        replace_with_number=\" \",\n",
        "        replace_with_currency_symbol=\" \",\n",
        "        lang=\"tr\"\n",
        "    )\n",
        "\n",
        "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/SENTIEMENT_MODEL/clean_sentiment_dataset.csv\")\n",
        "\n",
        "\n",
        "def normalize_label_to_id(x):\n",
        "    if isinstance(x, (int, np.integer)):\n",
        "        return int(x)\n",
        "    s = str(x).strip().lower()\n",
        "    if s in [\"0\", \"negative\", \"negatif\"]:\n",
        "        return 0\n",
        "    if s in [\"1\", \"notr\", \"neutral\", \"nötr\", \"notr.\", \"nötr.\"]:\n",
        "        return 1\n",
        "    if s in [\"2\", \"positive\", \"pozitif\"]:\n",
        "        return 2\n",
        "\n",
        "    return 1\n",
        "\n",
        "train_df[\"label_id\"] = train_df[\"label\"].apply(normalize_label_to_id)\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "vectorizer.fit(train_df[\"text\"].astype(str))\n",
        "\n",
        "\n",
        "train_vectors_all = vectorizer.transform(train_df[\"text\"].astype(str))\n",
        "\n",
        "class_data = {}\n",
        "for lid in [0, 1, 2]:\n",
        "    sub_df = train_df[train_df[\"label_id\"] == lid].copy()\n",
        "    sub_vectors = vectorizer.transform(sub_df[\"text\"].astype(str))\n",
        "    class_data[lid] = (sub_df.reset_index(drop=True), sub_vectors)\n",
        "\n",
        "\n",
        "def retrieve_similar_by_label(text, label_id, top_k=3):\n",
        "    \"\"\"\n",
        "    Sadece label_id ile aynı sınıftaki örnekler içinde cosine similarity ile top_k getirir.\n",
        "    \"\"\"\n",
        "    if label_id not in class_data:\n",
        "\n",
        "        vec = vectorizer.transform([text])\n",
        "        sims = cosine_similarity(vec, train_vectors_all).flatten()\n",
        "        top_idx = sims.argsort()[-top_k:][::-1]\n",
        "        return train_df.iloc[top_idx].copy()\n",
        "\n",
        "    sub_df, sub_vectors = class_data[label_id]\n",
        "    if len(sub_df) == 0:\n",
        "        return sub_df\n",
        "\n",
        "    vec = vectorizer.transform([text])\n",
        "    sims = cosine_similarity(vec, sub_vectors).flatten()\n",
        "    k = min(top_k, sims.shape[0])\n",
        "    top_idx = sims.argsort()[-k:][::-1]\n",
        "    return sub_df.iloc[top_idx].copy()\n",
        "\n",
        "\n",
        "def get_top_keywords(text, top_n=5):\n",
        "    tfidf_vec = vectorizer.transform([text])\n",
        "    feature_array = np.array(vectorizer.get_feature_names_out())\n",
        "    tfidf_sort = np.argsort(tfidf_vec.toarray()).flatten()[::-1]\n",
        "    return \", \".join(feature_array[tfidf_sort][:top_n])\n",
        "\n",
        "\n",
        "def predict_sentiment_with_probs(text):\n",
        "    original_text = text\n",
        "    cleaned = clean_text(text)\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        cleaned,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = F.softmax(outputs.logits, dim=1).cpu().numpy().flatten()\n",
        "        pred_id = int(np.argmax(probs))\n",
        "        pred_label = id2label[pred_id]\n",
        "\n",
        "    similar_examples = retrieve_similar_by_label(cleaned, pred_id, top_k=3)\n",
        "\n",
        "    explanation_lines = []\n",
        "    for _, row in similar_examples.iterrows():\n",
        "        example_text = str(row[\"text\"])\n",
        "        example_label = row[\"label\"]\n",
        "        keywords = get_top_keywords(example_text)\n",
        "        explanation_lines.append(\n",
        "            f\"- \\\"{example_text}\\\" (Etiket: {example_label} | Keywords: {keywords})\"\n",
        "        )\n",
        "    explanation = \"\\n\".join(explanation_lines)\n",
        "\n",
        "    prob_text = f\"Negative={probs[0]:.2f} | Notr={probs[1]:.2f} | Positive={probs[2]:.2f}\"\n",
        "\n",
        "    result_text = (\n",
        "        f\"Orijinal Metin:\\n{original_text}\\n\\n\"\n",
        "        f\"Temizlenmiş Metin:\\n{cleaned}\\n\\n\"\n",
        "        f\"Tahmin: {pred_label} ({prob_text})\"\n",
        "    )\n",
        "\n",
        "    return result_text, explanation\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_sentiment_with_probs,\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Metin gir...\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Tahmin + Temizlenmiş Metin + Olasılıklar\"),\n",
        "        gr.Textbox(label=\"Benzer Örnekler + Anahtar Kelimeler\")\n",
        "    ],\n",
        "    title=\"Türkçe Sentiment + Akıllı Temizleme + Label-Filtered Retrieval\",\n",
        "    description=\"Metin normalize edilir, model sınıflandırır, sonra SADECE aynı label içinden en benzer örnekler gösterilir.\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}